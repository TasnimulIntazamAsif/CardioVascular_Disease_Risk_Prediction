{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8de483fa",
   "metadata": {},
   "source": [
    "# CVD Risk Classification â€” Clean, High-Accuracy Pipeline\n",
    "**Auto-generated** on 2025-08-21 02:58:54.  \n",
    "This notebook rebuilds your workflow into clear, ordered cells and aims for **>85% accuracy** using robust preprocessing and a strong tree-based model (HistGradientBoosting / RandomForest / optional XGBoost).  \n",
    "It keeps class imbalance in mind and saves a ready-to-use pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbeca9c",
   "metadata": {},
   "source": [
    "## 0. Environment & Imports\n",
    "If you're running locally, ensure you have `scikit-learn`, `pandas`, `numpy`, and optionally `xgboost` installed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e36c7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q numpy pandas scikit-learn xgboost\n",
    "\n",
    "import os, re, math, json, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, HistGradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Optional: XGBoost if available\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971f8481",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614672af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url_string = 'https://github.com/Bishwaprotapi/Cardiovascular-Disease-Risk-Classification-Using-Machine-Learning-Techniques/blob/main/CVD_Dataset.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7ef86a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height (m)</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Abdominal Circumference (cm)</th>\n",
       "      <th>Blood Pressure (mmHg)</th>\n",
       "      <th>Total Cholesterol (mg/dL)</th>\n",
       "      <th>HDL (mg/dL)</th>\n",
       "      <th>Fasting Blood Sugar (mg/dL)</th>\n",
       "      <th>...</th>\n",
       "      <th>Physical Activity Level</th>\n",
       "      <th>Family History of CVD</th>\n",
       "      <th>CVD Risk Level</th>\n",
       "      <th>Height (cm)</th>\n",
       "      <th>Waist-to-Height Ratio</th>\n",
       "      <th>Systolic BP</th>\n",
       "      <th>Diastolic BP</th>\n",
       "      <th>Blood Pressure Category</th>\n",
       "      <th>Estimated LDL (mg/dL)</th>\n",
       "      <th>CVD Risk Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>69.100</td>\n",
       "      <td>1.710</td>\n",
       "      <td>23.600</td>\n",
       "      <td>86.200</td>\n",
       "      <td>125/79</td>\n",
       "      <td>248.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>171.000</td>\n",
       "      <td>0.504</td>\n",
       "      <td>125.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Elevated</td>\n",
       "      <td>140.0</td>\n",
       "      <td>17.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>F</td>\n",
       "      <td>55.0</td>\n",
       "      <td>118.700</td>\n",
       "      <td>1.690</td>\n",
       "      <td>41.600</td>\n",
       "      <td>82.500</td>\n",
       "      <td>139/70</td>\n",
       "      <td>162.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Y</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>169.000</td>\n",
       "      <td>0.488</td>\n",
       "      <td>139.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Hypertension Stage 1</td>\n",
       "      <td>82.0</td>\n",
       "      <td>20.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.830</td>\n",
       "      <td>26.900</td>\n",
       "      <td>106.700</td>\n",
       "      <td>104/77</td>\n",
       "      <td>103.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Y</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>183.000</td>\n",
       "      <td>0.583</td>\n",
       "      <td>104.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>44.0</td>\n",
       "      <td>108.300</td>\n",
       "      <td>1.800</td>\n",
       "      <td>33.400</td>\n",
       "      <td>96.600</td>\n",
       "      <td>140/83</td>\n",
       "      <td>134.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Y</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.537</td>\n",
       "      <td>140.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Hypertension Stage 1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>32.0</td>\n",
       "      <td>99.500</td>\n",
       "      <td>1.860</td>\n",
       "      <td>28.800</td>\n",
       "      <td>102.700</td>\n",
       "      <td>144/83</td>\n",
       "      <td>146.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>186.000</td>\n",
       "      <td>0.552</td>\n",
       "      <td>144.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Hypertension Stage 1</td>\n",
       "      <td>52.0</td>\n",
       "      <td>17.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>F</td>\n",
       "      <td>40.0</td>\n",
       "      <td>72.070</td>\n",
       "      <td>1.889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>95.326</td>\n",
       "      <td>119/66</td>\n",
       "      <td>157.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Y</td>\n",
       "      <td>LOW</td>\n",
       "      <td>188.894</td>\n",
       "      <td>0.505</td>\n",
       "      <td>119.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>67.0</td>\n",
       "      <td>14.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>F</td>\n",
       "      <td>78.0</td>\n",
       "      <td>85.877</td>\n",
       "      <td>1.825</td>\n",
       "      <td>24.426</td>\n",
       "      <td>112.340</td>\n",
       "      <td>102/115</td>\n",
       "      <td>241.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Low</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>182.485</td>\n",
       "      <td>0.616</td>\n",
       "      <td>102.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>Hypertension Stage 2</td>\n",
       "      <td>127.0</td>\n",
       "      <td>14.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>M</td>\n",
       "      <td>39.0</td>\n",
       "      <td>98.626</td>\n",
       "      <td>1.521</td>\n",
       "      <td>20.055</td>\n",
       "      <td>77.193</td>\n",
       "      <td>150/90</td>\n",
       "      <td>237.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>N</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>152.119</td>\n",
       "      <td>0.507</td>\n",
       "      <td>150.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Hypertension Stage 2</td>\n",
       "      <td>125.0</td>\n",
       "      <td>18.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>M</td>\n",
       "      <td>71.0</td>\n",
       "      <td>116.163</td>\n",
       "      <td>1.841</td>\n",
       "      <td>29.279</td>\n",
       "      <td>114.197</td>\n",
       "      <td>112/63</td>\n",
       "      <td>193.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>Y</td>\n",
       "      <td>INTERMEDIARY</td>\n",
       "      <td>184.059</td>\n",
       "      <td>0.620</td>\n",
       "      <td>112.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>79.0</td>\n",
       "      <td>15.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>F</td>\n",
       "      <td>78.0</td>\n",
       "      <td>111.627</td>\n",
       "      <td>1.867</td>\n",
       "      <td>22.017</td>\n",
       "      <td>97.692</td>\n",
       "      <td>134/67</td>\n",
       "      <td>218.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>...</td>\n",
       "      <td>High</td>\n",
       "      <td>N</td>\n",
       "      <td>HIGH</td>\n",
       "      <td>186.735</td>\n",
       "      <td>0.523</td>\n",
       "      <td>134.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Hypertension Stage 1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>15.463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1529 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex   Age  Weight (kg)  Height (m)     BMI  Abdominal Circumference (cm)  \\\n",
       "0      F  32.0       69.100       1.710  23.600                        86.200   \n",
       "1      F  55.0      118.700       1.690  41.600                        82.500   \n",
       "2      M   NaN          NaN       1.830  26.900                       106.700   \n",
       "3      M  44.0      108.300       1.800  33.400                        96.600   \n",
       "4      F  32.0       99.500       1.860  28.800                       102.700   \n",
       "...   ..   ...          ...         ...     ...                           ...   \n",
       "1524   F  40.0       72.070       1.889     NaN                        95.326   \n",
       "1525   F  78.0       85.877       1.825  24.426                       112.340   \n",
       "1526   M  39.0       98.626       1.521  20.055                        77.193   \n",
       "1527   M  71.0      116.163       1.841  29.279                       114.197   \n",
       "1528   F  78.0      111.627       1.867  22.017                        97.692   \n",
       "\n",
       "     Blood Pressure (mmHg)  Total Cholesterol (mg/dL)  HDL (mg/dL)  \\\n",
       "0                   125/79                      248.0         78.0   \n",
       "1                   139/70                      162.0         50.0   \n",
       "2                   104/77                      103.0         73.0   \n",
       "3                   140/83                      134.0         46.0   \n",
       "4                   144/83                      146.0         64.0   \n",
       "...                    ...                        ...          ...   \n",
       "1524                119/66                      157.0         60.0   \n",
       "1525               102/115                      241.0         84.0   \n",
       "1526                150/90                      237.0         82.0   \n",
       "1527                112/63                      193.0         84.0   \n",
       "1528                134/67                      218.0         68.0   \n",
       "\n",
       "      Fasting Blood Sugar (mg/dL)  ... Physical Activity Level  \\\n",
       "0                           111.0  ...                     Low   \n",
       "1                           135.0  ...                    High   \n",
       "2                           114.0  ...                    High   \n",
       "3                            91.0  ...                    High   \n",
       "4                           141.0  ...                    High   \n",
       "...                           ...  ...                     ...   \n",
       "1524                         93.0  ...                Moderate   \n",
       "1525                          NaN  ...                     Low   \n",
       "1526                        147.0  ...                    High   \n",
       "1527                        123.0  ...                    High   \n",
       "1528                        166.0  ...                    High   \n",
       "\n",
       "     Family History of CVD CVD Risk Level Height (cm) Waist-to-Height Ratio  \\\n",
       "0                        N   INTERMEDIARY     171.000                 0.504   \n",
       "1                        Y           HIGH     169.000                 0.488   \n",
       "2                        Y   INTERMEDIARY     183.000                 0.583   \n",
       "3                        Y   INTERMEDIARY         NaN                 0.537   \n",
       "4                        N   INTERMEDIARY     186.000                 0.552   \n",
       "...                    ...            ...         ...                   ...   \n",
       "1524                     Y            LOW     188.894                 0.505   \n",
       "1525                     N   INTERMEDIARY     182.485                 0.616   \n",
       "1526                     N   INTERMEDIARY     152.119                 0.507   \n",
       "1527                     Y   INTERMEDIARY     184.059                 0.620   \n",
       "1528                     N           HIGH     186.735                 0.523   \n",
       "\n",
       "      Systolic BP  Diastolic BP  Blood Pressure Category  \\\n",
       "0           125.0          79.0                 Elevated   \n",
       "1           139.0          70.0     Hypertension Stage 1   \n",
       "2           104.0          77.0                   Normal   \n",
       "3           140.0          83.0     Hypertension Stage 1   \n",
       "4           144.0          83.0     Hypertension Stage 1   \n",
       "...           ...           ...                      ...   \n",
       "1524        119.0          66.0                   Normal   \n",
       "1525        102.0         115.0     Hypertension Stage 2   \n",
       "1526        150.0          90.0     Hypertension Stage 2   \n",
       "1527        112.0          63.0                   Normal   \n",
       "1528        134.0          67.0     Hypertension Stage 1   \n",
       "\n",
       "      Estimated LDL (mg/dL) CVD Risk Score  \n",
       "0                     140.0         17.930  \n",
       "1                      82.0         20.510  \n",
       "2                       0.0         12.640  \n",
       "3                      58.0         16.360  \n",
       "4                      52.0         17.880  \n",
       "...                     ...            ...  \n",
       "1524                   67.0         14.300  \n",
       "1525                  127.0         14.805  \n",
       "1526                  125.0         18.251  \n",
       "1527                   79.0         15.316  \n",
       "1528                  120.0         15.463  \n",
       "\n",
       "[1529 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading Data Into Pandas Dataframe\n",
    "df = pd.read_csv('CVD_Dataset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9155f3",
   "metadata": {},
   "source": [
    "## 2. Inspect & Define Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5076d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      " CVD Risk Level\n",
      "HIGH            728\n",
      "INTERMEDIARY    581\n",
      "LOW             220\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columns by dtype:\n",
      "float64    14\n",
      "object      8\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# In your original notebook the target was inferred as 'CVD Risk Level'\n",
    "TARGET = 'CVD Risk Level'\n",
    "assert TARGET in df.columns, f\"Target column '{TARGET}' not found. Columns: {df.columns.tolist()}\"\n",
    "\n",
    "y = df[TARGET].astype(str).str.strip()\n",
    "X = df.drop(columns=[TARGET])\n",
    "\n",
    "print('Target distribution:\\n', y.value_counts())\n",
    "print('\\nColumns by dtype:')\n",
    "print(df.dtypes.value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396be48",
   "metadata": {},
   "source": [
    "## 3. Preprocessing\n",
    "- Numeric: median imputation + standard scaling  \n",
    "- Categorical: most-frequent imputation + one-hot encoding  \n",
    "We also automatically handle sparse/dense output differences across scikit-learn versions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c4edcd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 7, (1223, 21), (306, 21))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import __version__ as skver\n",
    "sk_major, sk_minor = [int(x) for x in skver.split('.')[:2]]\n",
    "ohe_kwargs = {'handle_unknown': 'ignore'}\n",
    "if (sk_major, sk_minor) >= (1, 2):\n",
    "    ohe_kwargs['sparse_output'] = False\n",
    "else:\n",
    "    ohe_kwargs['sparse'] = False\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = [c for c in X.columns if c not in cat_cols]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(**ohe_kwargs))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols),\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "len(num_cols), len(cat_cols), X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3782a36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this import\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Add this after defining y\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Use encoded labels for training\n",
    "y = y_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9955847",
   "metadata": {},
   "source": [
    "## 4. Quick Baselines\n",
    "We'll try a few fast models to get a sense of achievable accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ef403da",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['HIGH' 'INTERMEDIARY' 'LOW']\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     17\u001b[39m     xgb = XGBClassifier(\n\u001b[32m     18\u001b[39m         objective=\u001b[33m'\u001b[39m\u001b[33mmulti:softprob\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     19\u001b[39m         eval_metric=\u001b[33m'\u001b[39m\u001b[33mmlogloss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     25\u001b[39m         random_state=RANDOM_STATE\n\u001b[32m     26\u001b[39m     )\n\u001b[32m     27\u001b[39m     pipe = Pipeline(steps=[(\u001b[33m'\u001b[39m\u001b[33mprep\u001b[39m\u001b[33m'\u001b[39m, preprocess), (\u001b[33m'\u001b[39m\u001b[33mclf\u001b[39m\u001b[33m'\u001b[39m, xgb)])\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     scores = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     rows.append({\u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mXGBoost\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcv_mean_acc\u001b[39m\u001b[33m'\u001b[39m: scores.mean(), \u001b[33m'\u001b[39m\u001b[33mcv_std\u001b[39m\u001b[33m'\u001b[39m: scores.std(), \u001b[33m'\u001b[39m\u001b[33mcv_scores\u001b[39m\u001b[33m'\u001b[39m: scores})\n\u001b[32m     31\u001b[39m baseline_df = pd.DataFrame(rows).sort_values(\u001b[33m'\u001b[39m\u001b[33mcv_mean_acc\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:677\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    674\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    675\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    683\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    684\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:419\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    398\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m    399\u001b[39m results = parallel(\n\u001b[32m    400\u001b[39m     delayed(_fit_and_score)(\n\u001b[32m    401\u001b[39m         clone(estimator),\n\u001b[32m   (...)\u001b[39m\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[32m    417\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    422\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    423\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n\u001b[32m    424\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(scoring):\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:505\u001b[39m, in \u001b[36m_warn_or_raise_about_fit_failures\u001b[39m\u001b[34m(results, error_score)\u001b[39m\n\u001b[32m    498\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits == num_fits:\n\u001b[32m    499\u001b[39m     all_fits_failed_message = (\n\u001b[32m    500\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    501\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    502\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou can try to debug the error by setting error_score=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mraise\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    503\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m505\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[32m    507\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    508\u001b[39m     some_fits_failed_message = (\n\u001b[32m    509\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    510\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe score on these train-test partitions for these parameters\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    514\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    515\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py\", line 663, in fit\n    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"d:\\ML_ASIF_OWN PROJCET\\CardioVascular_Disease_Risk_Prediction\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1641, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got ['HIGH' 'INTERMEDIARY' 'LOW']\n"
     ]
    }
   ],
   "source": [
    "candidates = {\n",
    "    'HistGradientBoosting': HistGradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    'RandomForest': RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE, class_weight='balanced_subsample'),\n",
    "    'ExtraTrees': ExtraTreesClassifier(n_estimators=400, random_state=RANDOM_STATE, class_weight='balanced'),\n",
    "    'LogisticRegression': LogisticRegression(max_iter=2000, class_weight='balanced'),\n",
    "}\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "rows = []\n",
    "for name, clf in candidates.items():\n",
    "    pipe = Pipeline(steps=[('prep', preprocess), ('clf', clf)])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    rows.append({'model': name, 'cv_mean_acc': scores.mean(), 'cv_std': scores.std(), 'cv_scores': scores})\n",
    "    \n",
    "if XGB_AVAILABLE:\n",
    "    xgb = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        max_depth=6,\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.05,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "    pipe = Pipeline(steps=[('prep', preprocess), ('clf', xgb)])\n",
    "    scores = cross_val_score(pipe, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    rows.append({'model': 'XGBoost', 'cv_mean_acc': scores.mean(), 'cv_std': scores.std(), 'cv_scores': scores})\n",
    "\n",
    "baseline_df = pd.DataFrame(rows).sort_values('cv_mean_acc', ascending=False).reset_index(drop=True)\n",
    "baseline_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95db733",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning (Top Model)\n",
    "We tune the best-performing model from above. For speed, we use `RandomizedSearchCV` with a compact search space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43af5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose top model automatically from baseline results\n",
    "top_name = baseline_df.iloc[0]['model']\n",
    "print('Top baseline model:', top_name)\n",
    "\n",
    "if top_name == 'HistGradientBoosting':\n",
    "    base = HistGradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    param_distributions = {\n",
    "        'clf__max_depth': [None, 3, 5, 7],\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__max_leaf_nodes': [15, 31, 63],\n",
    "        'clf__min_samples_leaf': [10, 20, 30],\n",
    "    }\n",
    "elif top_name == 'RandomForest':\n",
    "    base = RandomForestClassifier(random_state=RANDOM_STATE, class_weight='balanced_subsample')\n",
    "    param_distributions = {\n",
    "        'clf__n_estimators': [200, 300, 400, 600],\n",
    "        'clf__max_depth': [None, 8, 12, 16],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "        'clf__max_features': ['auto', 'sqrt', 0.5],\n",
    "    }\n",
    "elif top_name == 'ExtraTrees':\n",
    "    base = ExtraTreesClassifier(random_state=RANDOM_STATE, class_weight='balanced')\n",
    "    param_distributions = {\n",
    "        'clf__n_estimators': [300, 400, 600, 800],\n",
    "        'clf__max_depth': [None, 8, 12, 16],\n",
    "        'clf__min_samples_split': [2, 5, 10],\n",
    "        'clf__min_samples_leaf': [1, 2, 4],\n",
    "        'clf__max_features': ['auto', 'sqrt', 0.5],\n",
    "    }\n",
    "elif top_name == 'LogisticRegression':\n",
    "    base = LogisticRegression(max_iter=4000, class_weight='balanced')\n",
    "    param_distributions = {\n",
    "        'clf__C': np.logspace(-2, 2, 10),\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    }\n",
    "elif top_name == 'XGBoost' and XGB_AVAILABLE:\n",
    "    base = XGBClassifier(\n",
    "        objective='multi:softprob',\n",
    "        eval_metric='mlogloss',\n",
    "        random_state=RANDOM_STATE,\n",
    "        tree_method='hist'\n",
    "    )\n",
    "    param_distributions = {\n",
    "        'clf__max_depth': [4, 6, 8],\n",
    "        'clf__n_estimators': [300, 500, 800],\n",
    "        'clf__learning_rate': [0.03, 0.05, 0.1],\n",
    "        'clf__subsample': [0.8, 1.0],\n",
    "        'clf__colsample_bytree': [0.7, 0.9, 1.0],\n",
    "    }\n",
    "else:\n",
    "    # Fallback to HistGradientBoosting if XGBoost wasn't available\n",
    "    top_name = 'HistGradientBoosting'\n",
    "    base = HistGradientBoostingClassifier(random_state=RANDOM_STATE)\n",
    "    param_distributions = {\n",
    "        'clf__max_depth': [None, 3, 5, 7],\n",
    "        'clf__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'clf__max_leaf_nodes': [15, 31, 63],\n",
    "        'clf__min_samples_leaf': [10, 20, 30],\n",
    "    }\n",
    "\n",
    "pipe = Pipeline(steps=[('prep', preprocess), ('clf', base)])\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=pipe,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=30,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE),\n",
    "    verbose=1,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print('Best CV accuracy:', search.best_score_)\n",
    "print('Best params:', search.best_params_)\n",
    "\n",
    "best_model = search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac428176",
   "metadata": {},
   "source": [
    "## 6. Final Evaluation on Holdout Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'Test Accuracy: {acc:.4f}\\n')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5,4))\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddcf6d1",
   "metadata": {},
   "source": [
    "## 7. Feature Importance (Permutation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a49f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(best_model, X_test, y_test, n_repeats=10, random_state=RANDOM_STATE, n_jobs=-1)\n",
    "importances = pd.DataFrame({\n",
    "    'feature': best_model.named_steps['prep'].get_feature_names_out(),\n",
    "    'importance_mean': r.importances_mean,\n",
    "    'importance_std': r.importances_std\n",
    "}).sort_values('importance_mean', ascending=False)\n",
    "importances.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865c3d1",
   "metadata": {},
   "source": [
    "## 8. Save Trained Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f75c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, os\n",
    "out_path = '/mnt/data/cvd_best_model.joblib'\n",
    "joblib.dump(best_model, out_path)\n",
    "print('Saved:', out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746f5f42",
   "metadata": {},
   "source": [
    "## 9. Inference Helper\n",
    "Use this snippet to load the model and predict on new data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576b1111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib, pandas as pd\n",
    "pipe = joblib.load('/mnt/data/cvd_best_model.joblib')\n",
    "\n",
    "# Example: take first 3 rows from the original dataset (without target)\n",
    "sample = X_test.iloc[:3].copy()\n",
    "print('Predictions:', pipe.predict(sample).tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
